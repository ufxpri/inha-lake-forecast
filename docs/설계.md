
# 구현목적 및 배경
다양한 데이터 소스로 부터 기반 데이터를 가져오고 실시간으로 변하는 기상 데이터에 반응적으로 시스템을 업데이트하고 서비스를 제공하기 위해 스케쥴러(airflow)를 사용하게 됨. 또한 많은 수의 사용자가 안정적으로 사용할 수 있도록 웹어플리케이션을  기반으로 동작하는것이 아닌 정적 페이지 형태로 서비스를 제공하는것을 목표로 했다. 따라서 사용자들은 웹어플리케이션을 거치지 않고도 각 cdn 에서 데이터를 바로 가져갈 수 있도록 하였다. 이외의 부가적인 사용자들의 직접 찍은 사진을 업로드 하기 위한 기능과 추후 알람 기능을 제공하는것을 기획하고 있다.

# airflow
선택이유
3.0 이 업데이트 되어 사용해보고 싶었음.
학습의 목적
모든 절차가 다 저장됨. 오류 발생시 알람도 받을 수 있음
스케쥴링된 작업이 정상작동하는지 유지보수에 모든 기능이 다 들어가있음.

# 실제 작성한 코드 + 설명
https://github.com/ufxpri/inha-lake-forecast
1. dags
(아직 dag 작성 안함.)
(대략적인 단계는 다음과 같을 것. 데이터 수집 -> 데이터 연산 -> 데이터 가공 -> 결과 페이지로 표현)

# 해당 기능이 서비스에서 차지하는 비중 또는 역할
해당 기능은 서비스의 전신 임. 데이터 수집부터 가공 표현 및 전달까지 모든 과정이 이 위에서 동작함.