"""
Weather ETL DAG for Ingyeongho Beauty Score System.

This DAG runs hourly to:
1. Fetch weather data from Korea Meteorological Administration API
2. Fetch air quality data from Korea Environment Corporation API
3. Calculate beauty score using the defined algorithm
4. Generate HTML component files for Nginx to serve
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import os
import json
import requests
import time
from typing import Dict, Any, Optional


def generate_hero_component(**context):
    """
    Generate hero.html component with current weather conditions.
    This file will be served by Nginx.
    """
    try:
        # Mock weather data (replace with real API calls)
        current_weather = {
            "temperature": 23,
            "condition": "ë§‘ìŒ",
            "icon": "â˜€ï¸",
            "humidity": 65,
            "wind_speed": 2.1,
            "description": "ì™„ë²½í•œ ì¸ê²½í˜¸ ê´€ëŒ ë‚ ì”¨ì…ë‹ˆë‹¤",
            "updated_at": datetime.now().strftime("%H:%M")
        }
        
        # Generate HTML content
        html_content = f"""<!-- Hero Component - Current Weather Conditions -->
<!-- Generated by Airflow at {datetime.now().isoformat()} -->
<div class="bg-gradient-to-br from-blue-500 to-indigo-600 text-white rounded-xl p-6 shadow-lg">
    <div class="flex items-center justify-between mb-4">
        <h3 class="text-xl font-bold">ğŸŒ¤ï¸ í˜„ì¬ ë‚ ì”¨</h3>
        <span class="text-sm opacity-80">{current_weather['updated_at']}</span>
    </div>
    
    <div class="flex items-center justify-between">
        <div class="flex items-center space-x-4">
            <div class="text-4xl">{current_weather['icon']}</div>
            <div>
                <div class="text-3xl font-bold">{current_weather['temperature']}Â°C</div>
                <div class="text-lg opacity-90">{current_weather['condition']}</div>
            </div>
        </div>
        
        <div class="text-right">
            <div class="text-sm opacity-80 mb-1">ìŠµë„: {current_weather['humidity']}%</div>
            <div class="text-sm opacity-80">ë°”ëŒ: {current_weather['wind_speed']}m/s</div>
        </div>
    </div>
    
    <div class="mt-4 pt-4 border-t border-white/20">
        <p class="text-sm opacity-90">{current_weather['description']}</p>
    </div>
</div>"""
        
        # Write to shared volume
        output_path = "/opt/airflow/nginx_html/components/hero.html"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… Generated hero.html at {output_path}")
        return {"status": "success", "file": "hero.html"}
        
    except Exception as e:
        print(f"âŒ Error generating hero component: {e}")
        raise


def generate_today_component(**context):
    """
    Generate today.html component with today's best time.
    """
    try:
        # Mock today's best time data (replace with real calculations)
        today_best = {
            "time": "06:30",
            "condition": "ì¼ì¶œ",
            "icon": "ğŸŒ…",
            "score": 95,
            "temperature": 18,
            "description": "06:30ì— ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ì¸ê²½í˜¸ë¥¼ ë§Œë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        }
        
        html_content = f"""<!-- Today Component - Best Time Today -->
<!-- Generated by Airflow at {datetime.now().isoformat()} -->
<div class="bg-gradient-to-br from-green-500 to-emerald-600 text-white rounded-xl p-6 shadow-lg">
    <div class="flex items-center justify-between mb-4">
        <h3 class="text-xl font-bold">â­ ì˜¤ëŠ˜ì˜ ë² ìŠ¤íŠ¸ íƒ€ì„</h3>
        <div class="bg-white/20 px-3 py-1 rounded-full text-sm font-semibold">
            BEST
        </div>
    </div>
    
    <div class="flex items-center justify-between">
        <div class="flex items-center space-x-4">
            <div class="text-4xl">{today_best['icon']}</div>
            <div>
                <div class="text-3xl font-bold">{today_best['time']}</div>
                <div class="text-lg opacity-90">{today_best['condition']}</div>
            </div>
        </div>
        
        <div class="text-right">
            <div class="text-2xl font-bold text-yellow-200">{today_best['score']}ì </div>
            <div class="text-sm opacity-80">{today_best['temperature']}Â°C</div>
        </div>
    </div>
    
    <div class="mt-4 pt-4 border-t border-white/20">
        <p class="text-sm opacity-90">{today_best['description']}</p>
    </div>
</div>"""
        
        output_path = "/opt/airflow/nginx_html/components/today.html"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… Generated today.html at {output_path}")
        return {"status": "success", "file": "today.html"}
        
    except Exception as e:
        print(f"âŒ Error generating today component: {e}")
        raise


def generate_week_component(**context):
    """
    Generate week.html component with this week's best day.
    """
    try:
        # Mock week's best day data (replace with real calculations)
        week_best = {
            "date": "11ì›” 22ì¼",
            "day": "ê¸ˆìš”ì¼",
            "condition": "êµ¬ë¦„ ì¡°ê¸ˆ",
            "icon": "ğŸŒ¤ï¸",
            "score": 92,
            "temperature": 21,
            "description": "ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼ì´ ê°€ì¥ ì•„ë¦„ë‹¤ìš´ ì¸ê²½í˜¸ë¥¼ ë³¼ ìˆ˜ ìˆëŠ” ë‚ ì…ë‹ˆë‹¤"
        }
        
        html_content = f"""<!-- Week Component - Best Day This Week -->
<!-- Generated by Airflow at {datetime.now().isoformat()} -->
<div class="bg-gradient-to-br from-purple-500 to-pink-600 text-white rounded-xl p-6 shadow-lg">
    <div class="flex items-center justify-between mb-4">
        <h3 class="text-xl font-bold">ğŸ† ì´ë²ˆ ì£¼ ë² ìŠ¤íŠ¸ ë°ì´</h3>
        <div class="bg-white/20 px-3 py-1 rounded-full text-sm font-semibold">
            WEEK BEST
        </div>
    </div>
    
    <div class="flex items-center justify-between">
        <div class="flex items-center space-x-4">
            <div class="text-4xl">{week_best['icon']}</div>
            <div>
                <div class="text-2xl font-bold">{week_best['date']}</div>
                <div class="text-xl font-semibold">{week_best['day']}</div>
                <div class="text-lg opacity-90">{week_best['condition']}</div>
            </div>
        </div>
        
        <div class="text-right">
            <div class="text-2xl font-bold text-yellow-200">{week_best['score']}ì </div>
            <div class="text-sm opacity-80">{week_best['temperature']}Â°C</div>
        </div>
    </div>
    
    <div class="mt-4 pt-4 border-t border-white/20">
        <p class="text-sm opacity-90">{week_best['description']}</p>
    </div>
</div>"""
        
        output_path = "/opt/airflow/nginx_html/components/week.html"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… Generated week.html at {output_path}")
        return {"status": "success", "file": "week.html"}
        
    except Exception as e:
        print(f"âŒ Error generating week component: {e}")
        raise


# DAG Definition
default_args = {
    'owner': 'ingyeongho-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 11, 21),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'weather_etl_dag',
    default_args=default_args,
    description='Generate weather component HTML files for Nginx',
    schedule_interval=timedelta(hours=1),  # Run every hour
    catchup=False,
    max_active_runs=1,
    tags=['weather', 'html-generation', 'ingyeongho']
)
    """
    Callback function for DAG failures.
    Logs DAG-level failure information.
    """
    dag_id = context['dag'].dag_id
    execution_date = context['execution_date']
    
    error_message = f"""
    DAG Failure Alert:
    - DAG ID: {dag_id}
    - Execution Date: {execution_date}
    - Multiple tasks failed or DAG failed to complete
    """
    
    print(f"DAG FAILURE: {error_message}")


# Default arguments for the DAG with enhanced error handling
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
    'start_date': datetime(2025, 11, 20),
    'on_failure_callback': log_task_failure,
}


# Database and Redis connection utilities for Airflow
def get_db_connection():
    """Get PostgreSQL database connection."""
    return psycopg2.connect(
        host=os.getenv('POSTGRES_HOST', 'postgres'),
        port=os.getenv('POSTGRES_PORT', '5432'),
        database=os.getenv('POSTGRES_DB', 'airflow'),
        user=os.getenv('POSTGRES_USER', 'airflow'),
        password=os.getenv('POSTGRES_PASSWORD', 'airflow')
    )


def get_redis_client():
    """Get Redis client connection."""
    return redis.Redis(
        host=os.getenv('REDIS_HOST', 'redis'),
        port=int(os.getenv('REDIS_PORT', '6379')),
        db=int(os.getenv('REDIS_DB', '0')),
        decode_responses=True
    )


# Task functions for data fetching
def fetch_weather_data(**context) -> Dict[str, Any]:
    """
    Fetch weather data from Korea Meteorological Administration API.
    Implements graceful degradation when external services fail.
    
    Returns:
        Dict containing weather data including temperature, conditions, precipitation
    """
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            # Korea Meteorological Administration API endpoint
            # Note: In production, use actual API key from environment variables
            api_key = os.getenv('KMA_API_KEY', 'test_api_key')
            base_url = os.getenv('KMA_API_URL', 'http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0')
            
            if api_key == 'test_api_key':
                print("Warning: Using test API key. Set KMA_API_KEY environment variable for production.")
            
            # For now, we'll use mock data structure that matches KMA API response
            # In production, this would make actual API calls with timeout and error handling
            weather_data = {
                'temperature': 15.5,  # Celsius
                'weather_condition': 'clear',  # clear, cloudy, rain, snow
                'precipitation_probability': 20,  # Percentage
                'humidity': 65,  # Percentage
                'wind_speed': 2.5,  # m/s
                'timestamp': datetime.now().isoformat(),
                'source': 'KMA',
                'retry_count': retry_count
            }
            
            # Validate data ranges
            if not isinstance(weather_data.get('temperature'), (int, float)):
                raise ValueError("Invalid temperature data type")
            if not -50 <= weather_data.get('temperature', 0) <= 60:
                raise ValueError(f"Temperature out of valid range: {weather_data.get('temperature')}")
            if not 0 <= weather_data.get('precipitation_probability', 0) <= 100:
                raise ValueError(f"Invalid precipitation probability: {weather_data.get('precipitation_probability')}")
            if not 0 <= weather_data.get('humidity', 0) <= 100:
                raise ValueError(f"Invalid humidity: {weather_data.get('humidity')}")
            
            # Store in XCom for downstream tasks
            context['task_instance'].xcom_push(key='weather_data', value=weather_data)
            
            print(f"Successfully fetched weather data (attempt {retry_count + 1}): {weather_data}")
            return weather_data
            
        except requests.exceptions.Timeout as e:
            retry_count += 1
            print(f"Timeout error fetching weather data (attempt {retry_count}/{max_retries}): {e}")
            if retry_count >= max_retries:
                break
            time.sleep(2 ** retry_count)  # Exponential backoff
            
        except requests.exceptions.ConnectionError as e:
            retry_count += 1
            print(f"Connection error fetching weather data (attempt {retry_count}/{max_retries}): {e}")
            if retry_count >= max_retries:
                break
            time.sleep(2 ** retry_count)  # Exponential backoff
            
        except requests.exceptions.RequestException as e:
            print(f"Request error fetching weather data: {e}")
            break  # Don't retry for other request errors
            
        except ValueError as e:
            print(f"Data validation error: {e}")
            break  # Don't retry for validation errors
            
        except Exception as e:
            print(f"Unexpected error in fetch_weather_data: {e}")
            break
    
    # Graceful degradation: try to get cached data from Redis
    try:
        redis_client = get_redis_client()
        cached_weather = redis_client.get('previous_weather_data')
        if cached_weather:
            cached_data = json.loads(cached_weather)
            print("Using cached weather data due to API failure")
            fallback_data = {
                'temperature': cached_data.get('temperature', 15.0),
                'weather_condition': cached_data.get('weather_condition', 'unknown'),
                'precipitation_probability': cached_data.get('precipitation_probability', 0),
                'humidity': 50,
                'wind_speed': 0,
                'timestamp': datetime.now().isoformat(),
                'source': 'cached_fallback',
                'retry_count': retry_count
            }
        else:
            raise Exception("No cached data available")
    except Exception as cache_error:
        print(f"Error accessing cached weather data: {cache_error}")
        # Final fallback to default values
        fallback_data = {
            'temperature': 15.0,
            'weather_condition': 'unknown',
            'precipitation_probability': 0,
            'humidity': 50,
            'wind_speed': 0,
            'timestamp': datetime.now().isoformat(),
            'source': 'default_fallback',
            'retry_count': retry_count
        }
    
    context['task_instance'].xcom_push(key='weather_data', value=fallback_data)
    print(f"Using fallback weather data after {retry_count} retries: {fallback_data}")
    return fallback_data


def fetch_air_quality_data(**context) -> Dict[str, Any]:
    """
    Fetch air quality data from Korea Environment Corporation API.
    Implements graceful degradation when external services fail.
    
    Returns:
        Dict containing air quality index and pollutant levels
    """
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            # Korea Environment Corporation API endpoint
            # Note: In production, use actual API key from environment variables
            api_key = os.getenv('KEC_API_KEY', 'test_api_key')
            base_url = os.getenv('KEC_API_URL', 'http://apis.data.go.kr/B552584/ArpltnInforInqireSvc')
            
            if api_key == 'test_api_key':
                print("Warning: Using test API key. Set KEC_API_KEY environment variable for production.")
            
            # For now, we'll use mock data structure that matches KEC API response
            # In production, this would make actual API calls with timeout and error handling
            air_quality_data = {
                'aqi': 45,  # Air Quality Index (0-500)
                'pm10': 35,  # PM10 concentration (Î¼g/mÂ³)
                'pm25': 15,  # PM2.5 concentration (Î¼g/mÂ³)
                'o3': 0.03,  # Ozone concentration (ppm)
                'no2': 0.02,  # Nitrogen dioxide (ppm)
                'co': 0.5,  # Carbon monoxide (ppm)
                'so2': 0.003,  # Sulfur dioxide (ppm)
                'grade': 'good',  # good, moderate, bad, very_bad
                'timestamp': datetime.now().isoformat(),
                'source': 'KEC',
                'retry_count': retry_count
            }
            
            # Validate data ranges
            if not isinstance(air_quality_data.get('aqi'), (int, float)):
                raise ValueError("Invalid AQI data type")
            if not 0 <= air_quality_data.get('aqi', 0) <= 500:
                raise ValueError(f"AQI out of valid range: {air_quality_data.get('aqi')}")
            if not 0 <= air_quality_data.get('pm10', 0) <= 1000:
                raise ValueError(f"PM10 out of valid range: {air_quality_data.get('pm10')}")
            if not 0 <= air_quality_data.get('pm25', 0) <= 500:
                raise ValueError(f"PM2.5 out of valid range: {air_quality_data.get('pm25')}")
            
            # Store in XCom for downstream tasks
            context['task_instance'].xcom_push(key='air_quality_data', value=air_quality_data)
            
            print(f"Successfully fetched air quality data (attempt {retry_count + 1}): {air_quality_data}")
            return air_quality_data
            
        except requests.exceptions.Timeout as e:
            retry_count += 1
            print(f"Timeout error fetching air quality data (attempt {retry_count}/{max_retries}): {e}")
            if retry_count >= max_retries:
                break
            time.sleep(2 ** retry_count)  # Exponential backoff
            
        except requests.exceptions.ConnectionError as e:
            retry_count += 1
            print(f"Connection error fetching air quality data (attempt {retry_count}/{max_retries}): {e}")
            if retry_count >= max_retries:
                break
            time.sleep(2 ** retry_count)  # Exponential backoff
            
        except requests.exceptions.RequestException as e:
            print(f"Request error fetching air quality data: {e}")
            break  # Don't retry for other request errors
            
        except ValueError as e:
            print(f"Data validation error: {e}")
            break  # Don't retry for validation errors
            
        except Exception as e:
            print(f"Unexpected error in fetch_air_quality_data: {e}")
            break
    
    # Graceful degradation: try to get cached data from Redis
    try:
        redis_client = get_redis_client()
        cached_air_quality = redis_client.get('previous_air_quality_data')
        if cached_air_quality:
            cached_data = json.loads(cached_air_quality)
            print("Using cached air quality data due to API failure")
            fallback_data = {
                'aqi': cached_data.get('aqi', 50),
                'pm10': cached_data.get('pm10', 30),
                'pm25': cached_data.get('pm25', 15),
                'o3': 0.03,
                'no2': 0.02,
                'co': 0.5,
                'so2': 0.003,
                'grade': 'moderate',
                'timestamp': datetime.now().isoformat(),
                'source': 'cached_fallback',
                'retry_count': retry_count
            }
        else:
            raise Exception("No cached data available")
    except Exception as cache_error:
        print(f"Error accessing cached air quality data: {cache_error}")
        # Final fallback to default values
        fallback_data = {
            'aqi': 50,
            'pm10': 30,
            'pm25': 15,
            'o3': 0.03,
            'no2': 0.02,
            'co': 0.5,
            'so2': 0.003,
            'grade': 'moderate',
            'timestamp': datetime.now().isoformat(),
            'source': 'default_fallback',
            'retry_count': retry_count
        }
    
    context['task_instance'].xcom_push(key='air_quality_data', value=fallback_data)
    print(f"Using fallback air quality data after {retry_count} retries: {fallback_data}")
    return fallback_data


def check_weather_change(**context) -> bool:
    """
    Check if there's a significant weather change that warrants triggering AI image generation.
    
    Significant changes include:
    - Weather condition change (e.g., clear to rain)
    - Temperature change > 5Â°C
    - AQI change > 50 points
    
    Returns:
        Boolean indicating whether to trigger AI Image DAG
    """
    try:
        # Get current weather data from XCom
        ti = context['task_instance']
        current_weather = ti.xcom_pull(key='weather_data', task_ids='fetch_weather_data')
        current_air_quality = ti.xcom_pull(key='air_quality_data', task_ids='fetch_air_quality_data')
        
        if not current_weather or not current_air_quality:
            print("No current weather data available, skipping change detection")
            return False
        
        # Get previous weather data from Redis
        redis_client = get_redis_client()
        prev_weather_str = redis_client.get('previous_weather_data')
        
        if not prev_weather_str:
            # First run, no previous data to compare
            print("No previous weather data, storing current data")
            redis_client.setex(
                'previous_weather_data',
                7200,  # 2 hours TTL
                json.dumps({
                    'weather_condition': current_weather.get('weather_condition'),
                    'temperature': current_weather.get('temperature'),
                    'aqi': current_air_quality.get('aqi')
                })
            )
            return False
        
        prev_weather = json.loads(prev_weather_str)
        
        # Check for significant changes
        weather_changed = (
            current_weather.get('weather_condition') != prev_weather.get('weather_condition')
        )
        
        temp_change = abs(
            current_weather.get('temperature', 0) - prev_weather.get('temperature', 0)
        )
        temp_changed = temp_change > 5
        
        aqi_change = abs(
            current_air_quality.get('aqi', 0) - prev_weather.get('aqi', 0)
        )
        aqi_changed = aqi_change > 50
        
        should_trigger = weather_changed or temp_changed or aqi_changed
        
        if should_trigger:
            print(f"Significant weather change detected:")
            print(f"  Weather: {prev_weather.get('weather_condition')} -> {current_weather.get('weather_condition')}")
            print(f"  Temperature change: {temp_change}Â°C")
            print(f"  AQI change: {aqi_change}")
            
            # Update previous weather data
            redis_client.setex(
                'previous_weather_data',
                7200,  # 2 hours TTL
                json.dumps({
                    'weather_condition': current_weather.get('weather_condition'),
                    'temperature': current_weather.get('temperature'),
                    'aqi': current_air_quality.get('aqi')
                })
            )
        else:
            print("No significant weather change detected")
        
        return should_trigger
        
    except Exception as e:
        print(f"Error checking weather change: {e}")
        return False


def calculate_beauty_score(**context) -> Dict[str, Any]:
    """
    Calculate beauty score based on weather and air quality data.
    Implements error handling for invalid data and storage failures.
    
    Algorithm:
    - Weather state: 40% weight
    - Temperature comfort: 30% weight
    - Air quality: 20% weight
    - Time adjustment: 10% weight
    - Golden hour bonus: +10 points
    - Precipitation penalty: -50 points (if >60% probability)
    - Air quality penalty: -30 points (if very bad)
    
    Returns:
        Dict containing calculated score and metadata
    """
    try:
        # Retrieve data from XCom with validation
        ti = context['task_instance']
        weather_data = ti.xcom_pull(key='weather_data', task_ids='fetch_weather_data')
        air_quality_data = ti.xcom_pull(key='air_quality_data', task_ids='fetch_air_quality_data')
        
        if not weather_data:
            print("Warning: No weather data available, using default values")
            weather_data = {
                'temperature': 15.0,
                'weather_condition': 'unknown',
                'precipitation_probability': 0
            }
        
        if not air_quality_data:
            print("Warning: No air quality data available, using default values")
            air_quality_data = {
                'aqi': 50
            }
        
        # Initialize base score
        base_score = 0
        
        # 1. Weather state score (40% weight, 0-40 points)
        weather_condition = weather_data.get('weather_condition', 'unknown')
        weather_scores = {
            'clear': 40,
            'partly_cloudy': 35,
            'cloudy': 25,
            'overcast': 15,
            'rain': 5,
            'snow': 10,
            'unknown': 20
        }
        weather_score = weather_scores.get(weather_condition, 20)
        base_score += weather_score
        
        # 2. Temperature comfort score (30% weight, 0-30 points)
        temperature = weather_data.get('temperature', 15)
        try:
            temperature = float(temperature)
        except (ValueError, TypeError):
            print(f"Warning: Invalid temperature value {temperature}, using default 15Â°C")
            temperature = 15.0
        
        # Optimal temperature range: 15-25Â°C
        if 15 <= temperature <= 25:
            temp_score = 30
        elif 10 <= temperature < 15 or 25 < temperature <= 30:
            temp_score = 25
        elif 5 <= temperature < 10 or 30 < temperature <= 35:
            temp_score = 15
        else:
            temp_score = 5
        base_score += temp_score
        
        # 3. Air quality score (20% weight, 0-20 points)
        aqi = air_quality_data.get('aqi', 50)
        try:
            aqi = float(aqi)
        except (ValueError, TypeError):
            print(f"Warning: Invalid AQI value {aqi}, using default 50")
            aqi = 50
        
        if aqi <= 50:  # Good
            air_score = 20
        elif aqi <= 100:  # Moderate
            air_score = 15
        elif aqi <= 150:  # Unhealthy for sensitive groups
            air_score = 10
        elif aqi <= 200:  # Unhealthy
            air_score = 5
        else:  # Very unhealthy or hazardous
            air_score = 0
        base_score += air_score
        
        # 4. Time adjustment score (10% weight, 0-10 points)
        current_hour = datetime.now().hour
        if 6 <= current_hour < 9 or 17 <= current_hour < 20:  # Golden hours
            time_score = 10
        elif 9 <= current_hour < 17:  # Daytime
            time_score = 8
        elif 20 <= current_hour < 22:  # Evening
            time_score = 6
        else:  # Night
            time_score = 2
        base_score += time_score
        
        # 5. Golden hour bonus (+10 points)
        # Approximately 30 minutes before/after sunset (simplified to 17:30-19:00)
        if 17.5 <= current_hour + (datetime.now().minute / 60) <= 19:
            base_score += 10
            is_golden_hour = True
        else:
            is_golden_hour = False
        
        # 6. Precipitation penalty (-50 points if >60% probability)
        precipitation_prob = weather_data.get('precipitation_probability', 0)
        try:
            precipitation_prob = float(precipitation_prob)
        except (ValueError, TypeError):
            print(f"Warning: Invalid precipitation probability {precipitation_prob}, using 0")
            precipitation_prob = 0
        
        if precipitation_prob > 60:
            base_score -= 50
        
        # 7. Air quality penalty (-30 points if very bad)
        if aqi > 200:  # Very bad air quality
            base_score -= 30
        
        # Clamp score to 0-100 range
        final_score = max(0, min(100, int(base_score)))
        
        # Determine status message based on score
        if final_score >= 80:
            status_message = "ì¸ìƒìƒ· ê°"
        elif final_score >= 60:
            status_message = "ì¢‹ì€ ì‹œê°„"
        elif final_score >= 40:
            status_message = "ê´œì°®ìŒ"
        elif final_score >= 30:
            status_message = "ë³„ë¡œ"
        else:
            status_message = "ë°©ì½• ì¶”ì²œ"
        
        # Prepare result data
        result = {
            'score': final_score,
            'status_message': status_message,
            'weather_condition': weather_condition,
            'temperature': temperature,
            'aqi': aqi,
            'is_golden_hour': is_golden_hour,
            'precipitation_probability': precipitation_prob,
            'timestamp': datetime.now().isoformat(),
            'components': {
                'weather_score': weather_score,
                'temp_score': temp_score,
                'air_score': air_score,
                'time_score': time_score,
            }
        }
        
        # Store in PostgreSQL with error handling
        db_success = False
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # Create table if not exists (for initial setup)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS beauty_scores (
                    id SERIAL PRIMARY KEY,
                    score INTEGER NOT NULL,
                    status_message VARCHAR(50),
                    weather_condition VARCHAR(50),
                    temperature FLOAT,
                    aqi INTEGER,
                    is_golden_hour BOOLEAN,
                    precipitation_probability INTEGER,
                    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    metadata JSONB
                )
            """)
            
            # Insert score record
            cursor.execute("""
                INSERT INTO beauty_scores 
                (score, status_message, weather_condition, temperature, aqi, 
                 is_golden_hour, precipitation_probability, metadata)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                final_score,
                status_message,
                weather_condition,
                temperature,
                int(aqi),
                is_golden_hour,
                int(precipitation_prob),
                json.dumps(result['components'])
            ))
            
            conn.commit()
            cursor.close()
            conn.close()
            db_success = True
            print(f"Successfully stored score in PostgreSQL: {final_score}")
            
        except psycopg2.Error as e:
            print(f"PostgreSQL error storing score: {e}")
            # Continue execution even if database write fails
        except Exception as e:
            print(f"Unexpected error storing score in PostgreSQL: {e}")
            # Continue execution even if database write fails
        
        # Update Redis cache with 1-hour TTL
        cache_success = False
        try:
            redis_client = get_redis_client()
            cache_data = {
                'score': final_score,
                'status_message': status_message,
                'weather_condition': weather_condition,
                'updated_at': datetime.now().isoformat()
            }
            redis_client.setex(
                'current_score',
                3600,  # 1 hour TTL
                json.dumps(cache_data)
            )
            cache_success = True
            print(f"Successfully cached score in Redis: {final_score}")
            
        except redis.RedisError as e:
            print(f"Redis error caching score: {e}")
            # Continue execution even if cache write fails
        except Exception as e:
            print(f"Unexpected error caching score in Redis: {e}")
            # Continue execution even if cache write fails
        
        # Add storage status to result
        result['storage_status'] = {
            'database': db_success,
            'cache': cache_success
        }
        
        print(f"Beauty score calculated: {final_score} - {status_message}")
        print(f"Storage status - Database: {db_success}, Cache: {cache_success}")
        
        return result
        
    except Exception as e:
        print(f"Critical error calculating beauty score: {e}")
        # Return a minimal result to prevent complete task failure
        fallback_result = {
            'score': 50,
            'status_message': "ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜",
            'weather_condition': 'unknown',
            'temperature': 15.0,
            'aqi': 50,
            'is_golden_hour': False,
            'precipitation_probability': 0,
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'storage_status': {
                'database': False,
                'cache': False
            }
        }
        print(f"Using fallback beauty score due to error: {fallback_result}")
        return fallback_result


# Define the DAG with enhanced error handling
with DAG(
    'weather_etl_dag',
    default_args=default_args,
    description='Hourly weather data collection and beauty score calculation',
    schedule='@hourly',
    catchup=False,
    tags=['weather', 'etl', 'beauty-score'],
    on_failure_callback=log_dag_failure,
    max_active_runs=1,  # Prevent overlapping runs
) as dag:
    
    # Task 1: Fetch weather data with enhanced retry configuration
    fetch_weather_task = PythonOperator(
        task_id='fetch_weather_data',
        python_callable=fetch_weather_data,
        provide_context=True,
        retries=3,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=log_task_failure,
    )
    
    # Task 2: Fetch air quality data with enhanced retry configuration
    fetch_air_quality_task = PythonOperator(
        task_id='fetch_air_quality_data',
        python_callable=fetch_air_quality_data,
        provide_context=True,
        retries=3,
        retry_delay=timedelta(minutes=5),
        on_failure_callback=log_task_failure,
    )
    
    # Task 3: Calculate beauty score and update cache
    calculate_score_task = PythonOperator(
        task_id='calculate_beauty_score',
        python_callable=calculate_beauty_score,
        provide_context=True,
        retries=2,  # Fewer retries for calculation task
        retry_delay=timedelta(minutes=2),
        on_failure_callback=log_task_failure,
    )
    
    # Task 4: Check for significant weather changes
    check_weather_change_task = PythonOperator(
        task_id='check_weather_change',
        python_callable=check_weather_change,
        provide_context=True,
        retries=1,  # Minimal retries for change detection
        retry_delay=timedelta(minutes=1),
        on_failure_callback=log_task_failure,
    )
    
    # Task 5: Trigger AI Image Generation DAG if weather changed significantly
    trigger_ai_image_dag = TriggerDagRunOperator(
        task_id='trigger_ai_image_generation',
        trigger_dag_id='ai_image_generation_dag',
        wait_for_completion=False,
        trigger_rule='all_success',
        retries=1,
        retry_delay=timedelta(minutes=2),
        on_failure_callback=log_task_failure,
    )
    
    # Set up task dependencies
    # Both weather and air quality data must be fetched before calculating score
    [fetch_weather_task, fetch_air_quality_task] >> calculate_score_task
    
    # After calculating score, check for weather changes
    calculate_score_task >> check_weather_change_task
    
    # Conditionally trigger AI image generation based on weather change
    # Note: In production, you would use a BranchPythonOperator or ShortCircuitOperator
    # to conditionally execute the trigger. For simplicity, we trigger on all runs.
    check_weather_change_task >> trigger_ai_image_dag

# Task Definitions
generate_hero_task = PythonOperator(
    task_id='generate_hero_component',
    python_callable=generate_hero_component,
    dag=dag,
)

generate_today_task = PythonOperator(
    task_id='generate_today_component',
    python_callable=generate_today_component,
    dag=dag,
)

generate_week_task = PythonOperator(
    task_id='generate_week_component',
    python_callable=generate_week_component,
    dag=dag,
)

# Task Dependencies - can run in parallel
generate_hero_task
generate_today_task  
generate_week_task